{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75290105-c8e5-48e6-af3b-a21dd00a53f7",
   "metadata": {},
   "source": [
    "# ML for optimization of fcm edges "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7661334a-74a9-4ca9-b505-6d1d4c9b7328",
   "metadata": {},
   "source": [
    "# Hebbian Learning \n",
    "\n",
    "## Task: optimize already existing FCM\n",
    "\n",
    "When the NHL algorithm has been applied for\n",
    "over 100 times AND both the termination conditions are  \n",
    "not met THEN experts are asked to reconstruct the FCM  \n",
    "model. The new weight matrix Winitial  \n",
    "new of the reconstructed\n",
    "FCM is used in Eq. (1) and calculates the Ai again, GO TO\n",
    "step 3.\n",
    "\n",
    "IF DOCi does not reach an accepted value THEN\n",
    "GO TO step 4, determine the parameter Z and implement\n",
    "the NHL technique again.   \n",
    "ELSE the process STOPs and\n",
    "the updated weight matrix is appropriate for the case-study\n",
    "scenario.\n",
    "#### NHL flow chart\n",
    "\n",
    "!['init vals'](figures/nhl_flow.png)yyy\n",
    "\n",
    "!['init vals'](figures/init.png)\n",
    "\n",
    "For more information about the algorithms, please check out \n",
    "**Unsupervised learning techniques for fine-tuning fuzzy cognitive\n",
    "map causal links** by\n",
    "Elpiniki I. Papageorgioua, Chrysostomos Styliosb, Peter P. Groumposa\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08c4eb60-d1f8-4cf4-9e63-e3d62388ed9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fcmpy.ml.hebbian.runner import simulator\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5da242d-0248-4e67-8fcd-315ec3f8c78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_init = np.asarray([[0,-0.4,-0.25,0,0.3],[0.36,0,0,0,0],[0.45,0,0,0,0],[-0.9,0,0,0,0],[0,0.6,0,0.3,0]])\n",
    "A0 = np.asarray([0.4,0.707,0.607,0.72,0.3])\n",
    "\n",
    "# DOCs \n",
    "doc = {0:[0.68,0.74],4:[0.74,0.8]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f041914d-6a7d-4a5e-b94d-980f2a17ae77",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Hebbian learning "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd3834cc-bb29-4f98-a020-9acc250c0d47",
   "metadata": {},
   "source": [
    "### Running the simulation and looping over different hyperparameters \n",
    "lambda (0.9,1.01,0.01)\n",
    "dacay coefficient (0.95,1.0,0.01)\n",
    "and learning rate (0.001,0.1,0.001)\n",
    "\n",
    "Append each results to the list (you will need it later) !\n",
    "\n",
    "```python \n",
    "fcmpy.ml.hebbian.runner.simulator\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a88f7751-a3c4-4c3d-a772-0c6beedc1d33",
   "metadata": {},
   "source": [
    "### Non-linear Hebbian learning \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb2cff57-0317-42ab-b0e2-b0c96c9da8c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "records = []\n",
    "for lbd in np.arange(0.9,1.01,0.01):\n",
    "    for decay in np.arange(0.95,1.0,0.01):\n",
    "        for learning_rate in np.arange(0.001,0.1,0.001): \n",
    "            run = simulator('nhl', learning_rate=learning_rate,decay=decay, A0=A0, W_init= W_init, doc=doc,lbd = lbd)\n",
    "            if run is not None:\n",
    "                records.append(run)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b2a29c-1c3d-48bf-9f52-e904895e9e6f",
   "metadata": {},
   "source": [
    "### Active Hebbian learning \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2207db9a-4bfb-4754-a01b-4ec14304dc87",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "recordsahl = []\n",
    "# for lbd in np.arange(0.9,1.01,0.01):\n",
    "lbd = 1\n",
    "for decay in np.arange(0.01,0.1,0.01): \n",
    "    for learning_rate in np.arange(0.001,0.1,0.001):\n",
    "        run = simulator('ahl', learning_rate=learning_rate,decay=decay, A0=A0, W_init= W_init, doc=doc, lbd = lbd)\n",
    "        # we do this loop for a particular initiated learning rate\n",
    "        if run is not None:\n",
    "            recordsahl.append(run)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
