<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.9.2" />
<title>fcmpy.ML.ahl_algorithm API documentation</title>
<meta name="description" content="For more information and details about the algorithm, please refer to â€¦" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>fcmpy.ML.ahl_algorithm</code></h1>
</header>
<section id="section-intro">
<p>For more information and details about the algorithm, please refer to</p>
<p>Active Hebbian learning algorithm
to train fuzzy cognitive maps
E.I. Papageorgiou a,*, C.D. Stylios b,1, P.P. Groumpos a</p>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">&#39;&#39;&#39;
For more information and details about the algorithm, please refer to

Active Hebbian learning algorithm
to train fuzzy cognitive maps
E.I. Papageorgiou a,*, C.D. Stylios b,1, P.P. Groumpos a
&#39;&#39;&#39;

import numpy as np
import math
import copy


class AHL:

    def __init__(self, nConcept, e=None, n=None, gamma=None, h=None, lbd=None, beta=None,b1=None,b2=None,l1=None,l2=None,mode=None):
        self.n = n if n is not None else 0.01  # learning rate
        self.gamma = gamma if gamma is not None else 0.02  # decay coef (different than for nhl)
        self.h = h if h is not None else 0  # tanh coef
        self.lbd = lbd if lbd is not None else 1 # steepness of continuous function
        self.termination1 = False
        self.termination2 = False
        self.termination3 = False
        self.W = np.zeros([1, nConcept, nConcept])  # initial W matrix
        self.A = np.zeros([1, nConcept])  # initial A matrix
        self.doc = []  # list of indexes which nodes are doc nodes
        self.doc_values = {}  # np array with min max value or dictionay with 2 values for each key
        self.e = e if e is not None else 0.005  # termination2 coefficient
        self.steps = 0
        self.nConcept = nConcept
        self.b1 = b1
        self.b2 = b2
        self.l1 = l1
        self.l2 = l2
        self.mode = mode if mode is not None else &#39;constant&#39;
        # or create a dictionary with parameters that is being checked each sept (or e.g. 100 steps) if the algorithm
        # doesnt finish update the dictionary

    def add_node(self, node, val, doc=False, doc_values=None, prt=False):
        &#39;&#39;&#39;

        :param node: node index
        :param val: value of the node
        :param doc: bool val if it is DOC
        :param doc_values: doc value as [t_min,t_max]
        :param prt: print the array of the nodes

        Adding the nodes to the map, we should add all the nodes before adding edges
        make sure you add not more nodes then you define when creating nhl
        e.g.
        map = nhl(nConcepts = ...,...)
        map.add(1,0.8,doc = [0.7,0.86])
        &#39;&#39;&#39;
        # check if it is the beginning of the simulation
        if self.steps != 0:
            raise Exception(&#39;cannot change the node values during the simulation&#39;)

        # checking if the values are the numbers
        try:
            float(node)
            float(val)
        except ValueError:
            raise Exception(&#39;node and val have to be numbers&#39;)

        # add the val to the initial activitation values
        self.A[0, node] = val

        if doc is True:
            # check for the if DOC values were added
            if doc_values is None or len(doc_values) != 2:
                raise Exception(&#39;you have to define DOC upper and &#39;)

            # check for the if DOC values were added
            try:
                float(doc_values[0])
                float(doc_values[1])
            except ValueError:
                raise Exception(&#39;lower and upper bound have to number in the array&#39;)

            self.doc.append(node)
            self.doc_values[node] = doc_values

        # if prt is true, show the values of A
        if prt is True:
            print(self.A)

    def add_edge(self, source, target, value, prt=False):
        &#39;&#39;&#39;

        :param source: index of the source node
        :param target: index of target node
        :param value: value of the edge (including sign
        :param prt: print the weight array

        Adding the edge between 2 nodes, we can define whether:
        - increament of source will cause increment of target ( value &gt;0)
        - increament of source will cause decrement of target ( value &lt;0)
        e.g.
        map = nhl(nConcepts = ...,...)
        map.add_node(1,0.8,doc=True,doc_values = [0.7,0.86])
        map.add_node(2,0.5)
        map.add_edge(1,2,-.8)
        &#39;&#39;&#39;

        # checking if node exist
        try:
            self.A[0,source]
            self.A[0, target]
        except IndexError:
            raise Exception(&#39;one of the nodes doesnt exist&#39;)

        try:
            float(value)
        except ValueError:
            raise Exception(&#39;value is not a number&#39;)

        self.W[0, source, target] = value

        # show values of W
        if prt is True:
            print(self.W)

    def sigmoid(self, x):
        &#39;&#39;&#39;
        :param x: input value
        :param lbd: normalizing param
        :param h: normalizing param
        :return: sigmoid activation function output

        Sigmoid function used for updating of the node value after each step
        &#39;&#39;&#39;
        # TODO try inintial lbd as 0.5, recommended in another article
        try:
            sigm = 1 / (1 + math.exp(-x * self.lbd))
        except OverflowError:
            print(&#39;number to big&#39; + str(x))
    
        return sigm
    

    def update_node(self, function=None):
        &#39;&#39;&#39;
        :param i: which concept, i.e. which column in weights

        updates node each step, we can indicate which function we want to use as an update function,
        most of HB algorithms are using sigmoid function, so it is defined as default. However, since some articles are
        proposing use of tanh, we also included this option here
        e.g.
        map.update_node(1)
        &#39;&#39;&#39;
        edge = 0
#
        if function is None or function == &#39;sigmoid&#39;:

                
#             vf = np.vectorize(self.sigmoid)
           
            self.A[-1] = 1/(1 + np.exp(-self.lbd*(self.A[-2] + self.W[-2]@self.A[-2])))
            
            
        elif (function == &#39;tangens&#39;) or (function == &#39;tanh&#39;) or (function == &#39;tan&#39;):
            self.A[self.steps, i] = math.tanh(A)
            
    def update_hyperparams(self):
        &#39;&#39;&#39;
        updating params according to 
        n = b1*exp(-l1*cycle_n) should be small, suggested values 0.02,-0.2
        gamma =  b2*exp(-l2*cycle_n) , choose values so -&gt;(1-gamma)~ 1:0.9, e.g. 0.08,1
        &#39;&#39;&#39;
        # decay coef
        self.gamma = self.b2*np.exp(-self.l2*self.steps)
        # learning rate 
        self.n = self.b1*np.exp(-self.l1*self.steps)

        
        
    def update_edge(self):
        &#39;&#39;&#39;
        :param i: index of the target node
        :param j: index of the source node
        option: 1,2,3

        in the literature many different functions were proposed, the function 1 and 2 are basically the same, however
        they in the option 2, we function sgn is not used
        the option 3 is taken from another articles
        e.g.
        map.update_edge(1,2,option = 2)
        &#39;&#39;&#39;
        
        # update parameters (each step, if mode is not == constant)
        if self.mode != &#39;constant&#39;:
            self.update_hyperparams()
            
        
            
        self.W[-1] = (1-self.gamma)*self.W[-2]+self.n*self.A[-2]*np.ones((self.nConcept,self.nConcept))*((self.A[-2]*np.ones((self.nConcept,self.nConcept))).T-self.W[-2]*(np.ones((self.nConcept,self.nConcept)))*self.A[-2])
            
                        
    def termination(self):
        &#39;&#39;&#39;
        :return: if termination conditionas are satifying

        checking if simulation is completed
        &#39;&#39;&#39;
        # changing for or
        if self.termination1 and self.termination2:# and self.termination3:
            return True
        else:
            return False

    def update_termination(self):
        &#39;&#39;&#39;
        updating termination conditions each step
        the values of termination conditions are False as default
        after each step the function is checking for 2 termination conditions i.e.
        - if the cost function value is decreasing
        - if change between doc is smaller than defined threshold (default is 0.02)
        :param step: which is the current step
        &#39;&#39;&#39;
        # check in nodes are in bounds

        if self.steps &lt; 2:
            #             print(&#39;too soon to finish&#39;)
            return
        
        #         1st termination condition
        
        self.termination1 = self.f1()

        # checking for either one or second term
        # check if there was a change between the DOC values greater than e
        # term2    
        if np.all([abs(self.A[-1]-self.A[-2])[i] &lt; self.e for i in self.doc]):
            self.termination2 = True
        
       
    def next_step(self):
        &#39;&#39;&#39;
        next step of the function
        increasing the dimension of np array for A and W
        &#39;&#39;&#39;

        # increase step value and dimensions of A and W
        self.steps += 1

        # add new axis to W and A and assign the value to 0

        self.W = np.resize(self.W, [self.steps + 1, self.W.shape[1], self.W.shape[2]])
        self.W[self.steps] = np.zeros([self.W.shape[1], self.W.shape[2]])

        self.A = np.resize(self.A, [self.steps + 1, self.A.shape[1]])
        self.A[self.steps] = np.zeros([1, self.A.shape[1]])

    
    def f1(self):
        score = 0
        for doc in self.doc_values.keys():
            t = sum(self.doc_values[doc])/2
            if (math.sqrt((self.A[-1,doc]-t)**2)&lt;math.sqrt((self.A[-2,doc]-t)**2)) and (math.sqrt((self.A[-2,doc]-t)**2)&lt;math.sqrt((self.A[-3,doc]-t)**2)):
                score +=1
        return score == len(self.doc)</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="fcmpy.ML.ahl_algorithm.AHL"><code class="flex name class">
<span>class <span class="ident">AHL</span></span>
<span>(</span><span>nConcept, e=None, n=None, gamma=None, h=None, lbd=None, beta=None, b1=None, b2=None, l1=None, l2=None, mode=None)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class AHL:

    def __init__(self, nConcept, e=None, n=None, gamma=None, h=None, lbd=None, beta=None,b1=None,b2=None,l1=None,l2=None,mode=None):
        self.n = n if n is not None else 0.01  # learning rate
        self.gamma = gamma if gamma is not None else 0.02  # decay coef (different than for nhl)
        self.h = h if h is not None else 0  # tanh coef
        self.lbd = lbd if lbd is not None else 1 # steepness of continuous function
        self.termination1 = False
        self.termination2 = False
        self.termination3 = False
        self.W = np.zeros([1, nConcept, nConcept])  # initial W matrix
        self.A = np.zeros([1, nConcept])  # initial A matrix
        self.doc = []  # list of indexes which nodes are doc nodes
        self.doc_values = {}  # np array with min max value or dictionay with 2 values for each key
        self.e = e if e is not None else 0.005  # termination2 coefficient
        self.steps = 0
        self.nConcept = nConcept
        self.b1 = b1
        self.b2 = b2
        self.l1 = l1
        self.l2 = l2
        self.mode = mode if mode is not None else &#39;constant&#39;
        # or create a dictionary with parameters that is being checked each sept (or e.g. 100 steps) if the algorithm
        # doesnt finish update the dictionary

    def add_node(self, node, val, doc=False, doc_values=None, prt=False):
        &#39;&#39;&#39;

        :param node: node index
        :param val: value of the node
        :param doc: bool val if it is DOC
        :param doc_values: doc value as [t_min,t_max]
        :param prt: print the array of the nodes

        Adding the nodes to the map, we should add all the nodes before adding edges
        make sure you add not more nodes then you define when creating nhl
        e.g.
        map = nhl(nConcepts = ...,...)
        map.add(1,0.8,doc = [0.7,0.86])
        &#39;&#39;&#39;
        # check if it is the beginning of the simulation
        if self.steps != 0:
            raise Exception(&#39;cannot change the node values during the simulation&#39;)

        # checking if the values are the numbers
        try:
            float(node)
            float(val)
        except ValueError:
            raise Exception(&#39;node and val have to be numbers&#39;)

        # add the val to the initial activitation values
        self.A[0, node] = val

        if doc is True:
            # check for the if DOC values were added
            if doc_values is None or len(doc_values) != 2:
                raise Exception(&#39;you have to define DOC upper and &#39;)

            # check for the if DOC values were added
            try:
                float(doc_values[0])
                float(doc_values[1])
            except ValueError:
                raise Exception(&#39;lower and upper bound have to number in the array&#39;)

            self.doc.append(node)
            self.doc_values[node] = doc_values

        # if prt is true, show the values of A
        if prt is True:
            print(self.A)

    def add_edge(self, source, target, value, prt=False):
        &#39;&#39;&#39;

        :param source: index of the source node
        :param target: index of target node
        :param value: value of the edge (including sign
        :param prt: print the weight array

        Adding the edge between 2 nodes, we can define whether:
        - increament of source will cause increment of target ( value &gt;0)
        - increament of source will cause decrement of target ( value &lt;0)
        e.g.
        map = nhl(nConcepts = ...,...)
        map.add_node(1,0.8,doc=True,doc_values = [0.7,0.86])
        map.add_node(2,0.5)
        map.add_edge(1,2,-.8)
        &#39;&#39;&#39;

        # checking if node exist
        try:
            self.A[0,source]
            self.A[0, target]
        except IndexError:
            raise Exception(&#39;one of the nodes doesnt exist&#39;)

        try:
            float(value)
        except ValueError:
            raise Exception(&#39;value is not a number&#39;)

        self.W[0, source, target] = value

        # show values of W
        if prt is True:
            print(self.W)

    def sigmoid(self, x):
        &#39;&#39;&#39;
        :param x: input value
        :param lbd: normalizing param
        :param h: normalizing param
        :return: sigmoid activation function output

        Sigmoid function used for updating of the node value after each step
        &#39;&#39;&#39;
        # TODO try inintial lbd as 0.5, recommended in another article
        try:
            sigm = 1 / (1 + math.exp(-x * self.lbd))
        except OverflowError:
            print(&#39;number to big&#39; + str(x))
    
        return sigm
    

    def update_node(self, function=None):
        &#39;&#39;&#39;
        :param i: which concept, i.e. which column in weights

        updates node each step, we can indicate which function we want to use as an update function,
        most of HB algorithms are using sigmoid function, so it is defined as default. However, since some articles are
        proposing use of tanh, we also included this option here
        e.g.
        map.update_node(1)
        &#39;&#39;&#39;
        edge = 0
#
        if function is None or function == &#39;sigmoid&#39;:

                
#             vf = np.vectorize(self.sigmoid)
           
            self.A[-1] = 1/(1 + np.exp(-self.lbd*(self.A[-2] + self.W[-2]@self.A[-2])))
            
            
        elif (function == &#39;tangens&#39;) or (function == &#39;tanh&#39;) or (function == &#39;tan&#39;):
            self.A[self.steps, i] = math.tanh(A)
            
    def update_hyperparams(self):
        &#39;&#39;&#39;
        updating params according to 
        n = b1*exp(-l1*cycle_n) should be small, suggested values 0.02,-0.2
        gamma =  b2*exp(-l2*cycle_n) , choose values so -&gt;(1-gamma)~ 1:0.9, e.g. 0.08,1
        &#39;&#39;&#39;
        # decay coef
        self.gamma = self.b2*np.exp(-self.l2*self.steps)
        # learning rate 
        self.n = self.b1*np.exp(-self.l1*self.steps)

        
        
    def update_edge(self):
        &#39;&#39;&#39;
        :param i: index of the target node
        :param j: index of the source node
        option: 1,2,3

        in the literature many different functions were proposed, the function 1 and 2 are basically the same, however
        they in the option 2, we function sgn is not used
        the option 3 is taken from another articles
        e.g.
        map.update_edge(1,2,option = 2)
        &#39;&#39;&#39;
        
        # update parameters (each step, if mode is not == constant)
        if self.mode != &#39;constant&#39;:
            self.update_hyperparams()
            
        
            
        self.W[-1] = (1-self.gamma)*self.W[-2]+self.n*self.A[-2]*np.ones((self.nConcept,self.nConcept))*((self.A[-2]*np.ones((self.nConcept,self.nConcept))).T-self.W[-2]*(np.ones((self.nConcept,self.nConcept)))*self.A[-2])
            
                        
    def termination(self):
        &#39;&#39;&#39;
        :return: if termination conditionas are satifying

        checking if simulation is completed
        &#39;&#39;&#39;
        # changing for or
        if self.termination1 and self.termination2:# and self.termination3:
            return True
        else:
            return False

    def update_termination(self):
        &#39;&#39;&#39;
        updating termination conditions each step
        the values of termination conditions are False as default
        after each step the function is checking for 2 termination conditions i.e.
        - if the cost function value is decreasing
        - if change between doc is smaller than defined threshold (default is 0.02)
        :param step: which is the current step
        &#39;&#39;&#39;
        # check in nodes are in bounds

        if self.steps &lt; 2:
            #             print(&#39;too soon to finish&#39;)
            return
        
        #         1st termination condition
        
        self.termination1 = self.f1()

        # checking for either one or second term
        # check if there was a change between the DOC values greater than e
        # term2    
        if np.all([abs(self.A[-1]-self.A[-2])[i] &lt; self.e for i in self.doc]):
            self.termination2 = True
        
       
    def next_step(self):
        &#39;&#39;&#39;
        next step of the function
        increasing the dimension of np array for A and W
        &#39;&#39;&#39;

        # increase step value and dimensions of A and W
        self.steps += 1

        # add new axis to W and A and assign the value to 0

        self.W = np.resize(self.W, [self.steps + 1, self.W.shape[1], self.W.shape[2]])
        self.W[self.steps] = np.zeros([self.W.shape[1], self.W.shape[2]])

        self.A = np.resize(self.A, [self.steps + 1, self.A.shape[1]])
        self.A[self.steps] = np.zeros([1, self.A.shape[1]])

    
    def f1(self):
        score = 0
        for doc in self.doc_values.keys():
            t = sum(self.doc_values[doc])/2
            if (math.sqrt((self.A[-1,doc]-t)**2)&lt;math.sqrt((self.A[-2,doc]-t)**2)) and (math.sqrt((self.A[-2,doc]-t)**2)&lt;math.sqrt((self.A[-3,doc]-t)**2)):
                score +=1
        return score == len(self.doc)</code></pre>
</details>
<h3>Methods</h3>
<dl>
<dt id="fcmpy.ML.ahl_algorithm.AHL.add_edge"><code class="name flex">
<span>def <span class="ident">add_edge</span></span>(<span>self, source, target, value, prt=False)</span>
</code></dt>
<dd>
<div class="desc"><p>:param source: index of the source node
:param target: index of target node
:param value: value of the edge (including sign
:param prt: print the weight array</p>
<p>Adding the edge between 2 nodes, we can define whether:
- increament of source will cause increment of target ( value &gt;0)
- increament of source will cause decrement of target ( value &lt;0)
e.g.
map = nhl(nConcepts = &hellip;,&hellip;)
map.add_node(1,0.8,doc=True,doc_values = [0.7,0.86])
map.add_node(2,0.5)
map.add_edge(1,2,-.8)</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def add_edge(self, source, target, value, prt=False):
    &#39;&#39;&#39;

    :param source: index of the source node
    :param target: index of target node
    :param value: value of the edge (including sign
    :param prt: print the weight array

    Adding the edge between 2 nodes, we can define whether:
    - increament of source will cause increment of target ( value &gt;0)
    - increament of source will cause decrement of target ( value &lt;0)
    e.g.
    map = nhl(nConcepts = ...,...)
    map.add_node(1,0.8,doc=True,doc_values = [0.7,0.86])
    map.add_node(2,0.5)
    map.add_edge(1,2,-.8)
    &#39;&#39;&#39;

    # checking if node exist
    try:
        self.A[0,source]
        self.A[0, target]
    except IndexError:
        raise Exception(&#39;one of the nodes doesnt exist&#39;)

    try:
        float(value)
    except ValueError:
        raise Exception(&#39;value is not a number&#39;)

    self.W[0, source, target] = value

    # show values of W
    if prt is True:
        print(self.W)</code></pre>
</details>
</dd>
<dt id="fcmpy.ML.ahl_algorithm.AHL.add_node"><code class="name flex">
<span>def <span class="ident">add_node</span></span>(<span>self, node, val, doc=False, doc_values=None, prt=False)</span>
</code></dt>
<dd>
<div class="desc"><p>:param node: node index
:param val: value of the node
:param doc: bool val if it is DOC
:param doc_values: doc value as [t_min,t_max]
:param prt: print the array of the nodes</p>
<p>Adding the nodes to the map, we should add all the nodes before adding edges
make sure you add not more nodes then you define when creating nhl
e.g.
map = nhl(nConcepts = &hellip;,&hellip;)
map.add(1,0.8,doc = [0.7,0.86])</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def add_node(self, node, val, doc=False, doc_values=None, prt=False):
    &#39;&#39;&#39;

    :param node: node index
    :param val: value of the node
    :param doc: bool val if it is DOC
    :param doc_values: doc value as [t_min,t_max]
    :param prt: print the array of the nodes

    Adding the nodes to the map, we should add all the nodes before adding edges
    make sure you add not more nodes then you define when creating nhl
    e.g.
    map = nhl(nConcepts = ...,...)
    map.add(1,0.8,doc = [0.7,0.86])
    &#39;&#39;&#39;
    # check if it is the beginning of the simulation
    if self.steps != 0:
        raise Exception(&#39;cannot change the node values during the simulation&#39;)

    # checking if the values are the numbers
    try:
        float(node)
        float(val)
    except ValueError:
        raise Exception(&#39;node and val have to be numbers&#39;)

    # add the val to the initial activitation values
    self.A[0, node] = val

    if doc is True:
        # check for the if DOC values were added
        if doc_values is None or len(doc_values) != 2:
            raise Exception(&#39;you have to define DOC upper and &#39;)

        # check for the if DOC values were added
        try:
            float(doc_values[0])
            float(doc_values[1])
        except ValueError:
            raise Exception(&#39;lower and upper bound have to number in the array&#39;)

        self.doc.append(node)
        self.doc_values[node] = doc_values

    # if prt is true, show the values of A
    if prt is True:
        print(self.A)</code></pre>
</details>
</dd>
<dt id="fcmpy.ML.ahl_algorithm.AHL.f1"><code class="name flex">
<span>def <span class="ident">f1</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def f1(self):
    score = 0
    for doc in self.doc_values.keys():
        t = sum(self.doc_values[doc])/2
        if (math.sqrt((self.A[-1,doc]-t)**2)&lt;math.sqrt((self.A[-2,doc]-t)**2)) and (math.sqrt((self.A[-2,doc]-t)**2)&lt;math.sqrt((self.A[-3,doc]-t)**2)):
            score +=1
    return score == len(self.doc)</code></pre>
</details>
</dd>
<dt id="fcmpy.ML.ahl_algorithm.AHL.next_step"><code class="name flex">
<span>def <span class="ident">next_step</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>next step of the function
increasing the dimension of np array for A and W</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def next_step(self):
    &#39;&#39;&#39;
    next step of the function
    increasing the dimension of np array for A and W
    &#39;&#39;&#39;

    # increase step value and dimensions of A and W
    self.steps += 1

    # add new axis to W and A and assign the value to 0

    self.W = np.resize(self.W, [self.steps + 1, self.W.shape[1], self.W.shape[2]])
    self.W[self.steps] = np.zeros([self.W.shape[1], self.W.shape[2]])

    self.A = np.resize(self.A, [self.steps + 1, self.A.shape[1]])
    self.A[self.steps] = np.zeros([1, self.A.shape[1]])</code></pre>
</details>
</dd>
<dt id="fcmpy.ML.ahl_algorithm.AHL.sigmoid"><code class="name flex">
<span>def <span class="ident">sigmoid</span></span>(<span>self, x)</span>
</code></dt>
<dd>
<div class="desc"><p>:param x: input value
:param lbd: normalizing param
:param h: normalizing param
:return: sigmoid activation function output</p>
<p>Sigmoid function used for updating of the node value after each step</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def sigmoid(self, x):
    &#39;&#39;&#39;
    :param x: input value
    :param lbd: normalizing param
    :param h: normalizing param
    :return: sigmoid activation function output

    Sigmoid function used for updating of the node value after each step
    &#39;&#39;&#39;
    # TODO try inintial lbd as 0.5, recommended in another article
    try:
        sigm = 1 / (1 + math.exp(-x * self.lbd))
    except OverflowError:
        print(&#39;number to big&#39; + str(x))

    return sigm</code></pre>
</details>
</dd>
<dt id="fcmpy.ML.ahl_algorithm.AHL.termination"><code class="name flex">
<span>def <span class="ident">termination</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>:return: if termination conditionas are satifying</p>
<p>checking if simulation is completed</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def termination(self):
    &#39;&#39;&#39;
    :return: if termination conditionas are satifying

    checking if simulation is completed
    &#39;&#39;&#39;
    # changing for or
    if self.termination1 and self.termination2:# and self.termination3:
        return True
    else:
        return False</code></pre>
</details>
</dd>
<dt id="fcmpy.ML.ahl_algorithm.AHL.update_edge"><code class="name flex">
<span>def <span class="ident">update_edge</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>:param i: index of the target node
:param j: index of the source node
option: 1,2,3</p>
<p>in the literature many different functions were proposed, the function 1 and 2 are basically the same, however
they in the option 2, we function sgn is not used
the option 3 is taken from another articles
e.g.
map.update_edge(1,2,option = 2)</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def update_edge(self):
    &#39;&#39;&#39;
    :param i: index of the target node
    :param j: index of the source node
    option: 1,2,3

    in the literature many different functions were proposed, the function 1 and 2 are basically the same, however
    they in the option 2, we function sgn is not used
    the option 3 is taken from another articles
    e.g.
    map.update_edge(1,2,option = 2)
    &#39;&#39;&#39;
    
    # update parameters (each step, if mode is not == constant)
    if self.mode != &#39;constant&#39;:
        self.update_hyperparams()
        
    
        
    self.W[-1] = (1-self.gamma)*self.W[-2]+self.n*self.A[-2]*np.ones((self.nConcept,self.nConcept))*((self.A[-2]*np.ones((self.nConcept,self.nConcept))).T-self.W[-2]*(np.ones((self.nConcept,self.nConcept)))*self.A[-2])</code></pre>
</details>
</dd>
<dt id="fcmpy.ML.ahl_algorithm.AHL.update_hyperparams"><code class="name flex">
<span>def <span class="ident">update_hyperparams</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>updating params according to
n = b1<em>exp(-l1</em>cycle_n) should be small, suggested values 0.02,-0.2
gamma =
b2<em>exp(-l2</em>cycle_n) , choose values so -&gt;(1-gamma)~ 1:0.9, e.g. 0.08,1</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def update_hyperparams(self):
    &#39;&#39;&#39;
    updating params according to 
    n = b1*exp(-l1*cycle_n) should be small, suggested values 0.02,-0.2
    gamma =  b2*exp(-l2*cycle_n) , choose values so -&gt;(1-gamma)~ 1:0.9, e.g. 0.08,1
    &#39;&#39;&#39;
    # decay coef
    self.gamma = self.b2*np.exp(-self.l2*self.steps)
    # learning rate 
    self.n = self.b1*np.exp(-self.l1*self.steps)</code></pre>
</details>
</dd>
<dt id="fcmpy.ML.ahl_algorithm.AHL.update_node"><code class="name flex">
<span>def <span class="ident">update_node</span></span>(<span>self, function=None)</span>
</code></dt>
<dd>
<div class="desc"><p>:param i: which concept, i.e. which column in weights</p>
<p>updates node each step, we can indicate which function we want to use as an update function,
most of HB algorithms are using sigmoid function, so it is defined as default. However, since some articles are
proposing use of tanh, we also included this option here
e.g.
map.update_node(1)</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">    def update_node(self, function=None):
        &#39;&#39;&#39;
        :param i: which concept, i.e. which column in weights

        updates node each step, we can indicate which function we want to use as an update function,
        most of HB algorithms are using sigmoid function, so it is defined as default. However, since some articles are
        proposing use of tanh, we also included this option here
        e.g.
        map.update_node(1)
        &#39;&#39;&#39;
        edge = 0
#
        if function is None or function == &#39;sigmoid&#39;:

                
#             vf = np.vectorize(self.sigmoid)
           
            self.A[-1] = 1/(1 + np.exp(-self.lbd*(self.A[-2] + self.W[-2]@self.A[-2])))
            
            
        elif (function == &#39;tangens&#39;) or (function == &#39;tanh&#39;) or (function == &#39;tan&#39;):
            self.A[self.steps, i] = math.tanh(A)</code></pre>
</details>
</dd>
<dt id="fcmpy.ML.ahl_algorithm.AHL.update_termination"><code class="name flex">
<span>def <span class="ident">update_termination</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>updating termination conditions each step
the values of termination conditions are False as default
after each step the function is checking for 2 termination conditions i.e.
- if the cost function value is decreasing
- if change between doc is smaller than defined threshold (default is 0.02)
:param step: which is the current step</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def update_termination(self):
    &#39;&#39;&#39;
    updating termination conditions each step
    the values of termination conditions are False as default
    after each step the function is checking for 2 termination conditions i.e.
    - if the cost function value is decreasing
    - if change between doc is smaller than defined threshold (default is 0.02)
    :param step: which is the current step
    &#39;&#39;&#39;
    # check in nodes are in bounds

    if self.steps &lt; 2:
        #             print(&#39;too soon to finish&#39;)
        return
    
    #         1st termination condition
    
    self.termination1 = self.f1()

    # checking for either one or second term
    # check if there was a change between the DOC values greater than e
    # term2    
    if np.all([abs(self.A[-1]-self.A[-2])[i] &lt; self.e for i in self.doc]):
        self.termination2 = True</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="fcmpy.ML" href="index.html">fcmpy.ML</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="fcmpy.ML.ahl_algorithm.AHL" href="#fcmpy.ML.ahl_algorithm.AHL">AHL</a></code></h4>
<ul class="two-column">
<li><code><a title="fcmpy.ML.ahl_algorithm.AHL.add_edge" href="#fcmpy.ML.ahl_algorithm.AHL.add_edge">add_edge</a></code></li>
<li><code><a title="fcmpy.ML.ahl_algorithm.AHL.add_node" href="#fcmpy.ML.ahl_algorithm.AHL.add_node">add_node</a></code></li>
<li><code><a title="fcmpy.ML.ahl_algorithm.AHL.f1" href="#fcmpy.ML.ahl_algorithm.AHL.f1">f1</a></code></li>
<li><code><a title="fcmpy.ML.ahl_algorithm.AHL.next_step" href="#fcmpy.ML.ahl_algorithm.AHL.next_step">next_step</a></code></li>
<li><code><a title="fcmpy.ML.ahl_algorithm.AHL.sigmoid" href="#fcmpy.ML.ahl_algorithm.AHL.sigmoid">sigmoid</a></code></li>
<li><code><a title="fcmpy.ML.ahl_algorithm.AHL.termination" href="#fcmpy.ML.ahl_algorithm.AHL.termination">termination</a></code></li>
<li><code><a title="fcmpy.ML.ahl_algorithm.AHL.update_edge" href="#fcmpy.ML.ahl_algorithm.AHL.update_edge">update_edge</a></code></li>
<li><code><a title="fcmpy.ML.ahl_algorithm.AHL.update_hyperparams" href="#fcmpy.ML.ahl_algorithm.AHL.update_hyperparams">update_hyperparams</a></code></li>
<li><code><a title="fcmpy.ML.ahl_algorithm.AHL.update_node" href="#fcmpy.ML.ahl_algorithm.AHL.update_node">update_node</a></code></li>
<li><code><a title="fcmpy.ML.ahl_algorithm.AHL.update_termination" href="#fcmpy.ML.ahl_algorithm.AHL.update_termination">update_termination</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.9.2</a>.</p>
</footer>
</body>
</html>